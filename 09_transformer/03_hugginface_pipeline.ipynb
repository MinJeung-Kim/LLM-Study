{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98c004f",
   "metadata": {},
   "source": [
    "## HugginFace Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd826f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q kobert-transformers\n",
    "!pip install -q python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e80135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccec54",
   "metadata": {},
   "source": [
    "### NLP Tasks\n",
    "\n",
    "주어진 Task에서 사전 훈련된 모델을 사용하는 가장 간단한 방법은  `pipeline`을 사용하는 것이다.\n",
    "\n",
    "- **기계 번역(Translation)**: 텍스트를 다른 언어로 번역한다.  \n",
    "- **감정 분석(Text Classification)**: 텍스트가 긍정적인지 부정적인지 분류할 수 있다.  \n",
    "- **텍스트 생성(Text Generation)**: 프롬프트를 입력하면 모델이 후속 텍스트를 생성한다.  \n",
    "- **이름 개체 인식(NER)**: 입력 문장의 각 단어가 어떤 개체(예: 사람, 장소 등)를 나타내는지 식별할 수 있다.  \n",
    "- **질문 답변(Question Answering)**: 컨텍스트와 질문을 입력하면 모델이 컨텍스트에서 적절한 답변을 추출한다.  \n",
    "- **마스킹된 텍스트 채우기(Fill-Mask)**: 마스킹된 단어가 포함된 텍스트(`[MASK]`로 대체됨)를 입력하면 공백을 채울 단어를 예측한다.  \n",
    "- **요약(Summarization)**: 긴 텍스트의 요약을 생성한다.  \n",
    "- **특징 추출(Feature Extraction)**: 텍스트의 텐서 표현을 반환하여 특성을 추출한다.  \n",
    "- **Zero-Shot 분류(Zero-Shot Classification)**: 레이블이 없는 데이터에 대해 사전 정의된 레이블에 맞는 분류를 수행한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f5a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4dc35",
   "metadata": {},
   "source": [
    "#### 기계 번역\n",
    "\n",
    "- 모델 레포\n",
    "https://huggingface.co/Helsinki-NLP/opus-mt-ko-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d150896",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7c658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf389d620d84c07a89043e2be1d7961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  27%|##6       | 83.9M/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ff0b1aaa4442ef8d5ffe8a760f1c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaad6e0f02f4a928dcc118ab7deb784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969aeb5b15ab4b579ce9a958cedde28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fefc156af6441f8ac56845d4514986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/842k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc7a016bf064ae5a80c240036a52c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440c0800ab7448d18d3b5a51c8429a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roxie\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text2text_generation.TranslationPipeline at 0x21326fd8ec0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한국어 -> 영어 번역 파이프라인 생성\n",
    "\n",
    "translation = pipeline(\n",
    "    'translation',\n",
    "    model='Helsinki-NLP/opus-mt-ko-en', \n",
    "    tokenizer='Helsinki-NLP/opus-mt-ko-en'\n",
    "    )\n",
    "\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ec7c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'I want to go home now.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation(\"저 지금 집에 가고 싶어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "311efcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"It's snowy. It's snowy.\"},\n",
       " {'translation_text': '19th stage.'},\n",
       " {'translation_text': \"It doesn't make any sense to me.\"},\n",
       " {'translation_text': \"I can't be a genius.\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation([\n",
    "    \"눈이 내려서 눈이 시려요\",\n",
    "    \"19기 화이팅\",\n",
    "    '말을 보니 말이 안나와요.',\n",
    "    '난 천재가 아닐수가 없다'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912e6e2",
   "metadata": {},
   "source": [
    "#### 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab2bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501c5ad64ce14728bf08dc259db05130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roxie\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\roxie\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46658798c508496494af0bcb35c347a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b2fe2da07d495e86ad5b14b0145010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8e75c0dd314105814ad6aacc9c517a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# huggingface에서 제공하는 감성 분석 파이프라인 사용\n",
    "sentiment_clf = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5147596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998770952224731}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_clf(\"I'm very happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f4dfa",
   "metadata": {},
   "source": [
    "- 한국어 감성 분석 모델  \n",
    "https://huggingface.co/sangrimlee/bert-base-multilingual-cased-nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "932dca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ko_sentiment_clf = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='sangrimlee/bert-base-multilingual-cased-nsmc', \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
