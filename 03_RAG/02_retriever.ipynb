{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d79ba7",
   "metadata": {},
   "source": [
    "## Retriever\n",
    "\n",
    "Retriever는 주어진 쿼리(질문)에 대해 관련성이 높은 문서나 정보를 데이터베이스나 문서 컬렉션에서 찾아내는 시스템.\n",
    "\n",
    "#### 주요 기능\n",
    "1. 의미 기반 검색(Semantic Search)\n",
    "    - 키워드 매칭이 아닌 의미적 유사도를 기반으로 문서 검색\n",
    "    - 임베딩 벡터 간의 유사도를 계산하여 관련 문서 추출\n",
    "\n",
    "2. 효율적인 검색\n",
    "    - 대량의 문서에서 빠르게 관련 정보를 찾아냄\n",
    "    - 벡터 데이터베이스(FAISS, Pinecone, Chroma 등) 활용\n",
    "\n",
    "3. 컨텍스트 제공    - \n",
    "LLM에게 답변 생성을 위한 관련 컨텍스트 제공\n",
    "    - 환각(hallucination) 감소 및 정확도 향상\n",
    "\n",
    "#### Retriever의 종류\n",
    "1. Dense Retriever\n",
    "    - 신경망 기반 임베딩 사용\n",
    "    - 예: Sentence Transformers, OpenAI Embeddings\n",
    "\n",
    "2. Sparse Retriever\n",
    "    - 키워드 기반 검색\n",
    "    - 예: BM25, TF-IDF\n",
    "\n",
    "3. Hybrid Retriever\n",
    "    - Dense + Sparse 방식 결합\n",
    "    - 더 나은 검색 성능 제공\n",
    "\n",
    "#### RAG에서의 역할\n",
    "사용자 질문 → Retriever → 관련 문서 검색 → LLM → 답변 생성\n",
    "\n",
    "> Retriever는 외부 지식을 활용하여 LLM이 더 정확하고 최신의 정보를 기반으로 답변할 수 있도록 돕는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4354b22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # .env 파일에서 환경 변수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7d331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19284730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question.\\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000017B36570550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000017B36571090>, root_client=<openai.OpenAI object at 0x0000017B36570CD0>, root_async_client=<openai.AsyncOpenAI object at 0x0000017B36570E10>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000017B36571450>, search_kwargs={'k': 3}))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RetrievalQA : 문서 검색 및 질문 응답 체인\n",
    "# - 문서 검색 기능과 질문 응답 기능을 결합한 체인\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI # OpenAI 챗 모델\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 모델 초기화  \n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\", \n",
    "    temperature=0 # 창의성 제어, 0은 가장 결정적인 응답\n",
    "    )\n",
    "\n",
    "vector_store = FAISS.load_local(\n",
    "    \"./db/faiss_vector_store\",  # 저장된 경로\n",
    "    embedding_model, # 임베딩 모델\n",
    "    allow_dangerous_deserialization=True # FAISS 벡터 스토어 로드 시 필요(보안 경고 무시)\n",
    "    )\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 문서 검색기 설정 (예: 벡터 데이터베이스에서 검색)\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "\n",
    "    # 문서 검색기 설정\n",
    "    retriever=retriever,\n",
    "\n",
    "    # 문서 결합 방식 지정(\"stuff\", \"map_reduce\" 등),  \n",
    "    # stuff : retriever로 검색된 모든 문서를 하나로 합쳐 처리\n",
    "    chain_type=\"stuff\" \n",
    ")\n",
    "\n",
    "retrieval_qa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcd1ce",
   "metadata": {},
   "source": [
    "#### Tom Sawyer라는 책에 대한 질의 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf11b081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Tom Sawyer 책의 주요 줄거리와 내용을 요약해줘',\n",
       " 'result': '\"톰 소여의 모험\"은 마크 트웨인이 쓴 소설로, 19세기 미국의 작은 마을에서 자라는 소년 톰 소여의 이야기를 다룹니다. 톰은 모험을 사랑하는 소년으로, 친구인 허크 핀과 함께 다양한 모험을 경험합니다. \\n\\n소설은 톰이 보물 찾기를 제안하며 시작되며, 그는 허크와 함께 여러 가지 사건에 휘말리게 됩니다. 톰은 묘지에서의 모험과 동굴에서의 사건을 겪으며, 인종 조와 같은 위협적인 인물과 마주하게 됩니다. 또한, 톰은 친구 베키와의 관계에서도 갈등을 겪고, 친구 머프 포터의 재판에 참여하여 그를 도우려는 결심을 하게 됩니다.\\n\\n이 이야기는 우정, 용기, 그리고 도덕적 선택에 대한 주제를 탐구하며, 톰의 성장과 모험을 통해 독자에게 재미와 교훈을 제공합니다.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tom Sawyer 책의 전체 줄거리 요약 질문\n",
    "retrieval_qa.invoke('Tom Sawyer 책의 주요 줄거리와 내용을 요약해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ddb101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '마을 무덤에 있떤 남자를 누가 죽였나요?', 'result': 'Injun Joe가 의사를 죽였습니다.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_qa.invoke('마을 무덤에 있떤 남자를 누가 죽였나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545310e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '인디언 조가 누구를 죽였나요?', 'result': '인디언 조는 의사를 죽였습니다.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_qa.invoke('인디언 조가 누구를 죽였나요?') # 질문에 대한 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ddc682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '인디언 조는 의사를 어떻게 죽였나요?', 'result': '인디언 조는 의사를 칼로 죽였습니다.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_qa.invoke('인디언 조는 의사를 어떻게 죽였나요?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
