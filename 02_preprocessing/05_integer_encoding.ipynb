{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5d4390",
   "metadata": {},
   "source": [
    "### 정수 인코딩(Integer Encoding)\n",
    "\n",
    "- 자연어 처리는 텍스트 데이터를 숫자로 변환하여 컴퓨터가 이해할 수 있도록 만드는 것이 핵심.\n",
    "- 정수 인코딩을 수행하여 텍스트 데이터에 고유한 인덱스를 부여.\n",
    "- 이러한 인코딩 과정은 전처리 과정에서 필수적이며 각 단어의 등장 빈도에 따라 인덱스를 부여하는 것이 일반적.\n",
    "- 단어 수를 5,000개로 제한하는 것은 모델 학습에 필요한 메모리와 계산 자원(리소스, 메모리 등)을 줄이기 위함.  \n",
    "    => 등장 빈도가 낮은 단어는 제외하고 상위 5,000개 단어만 선택하는 것이 일반적."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb28dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"The Little Prince, written by Antoine de Saint-Exupéry, is a poetic tale about a young prince who travels from his home planet to Earth. The story begins with a pilot stranded in the Sahara Desert after his plane crashes. While trying to fix his plane, he meets a mysterious young boy, the Little Prince.\n",
    "\n",
    "The Little Prince comes from a small asteroid called B-612, where he lives alone with a rose that he loves deeply. He recounts his journey to the pilot, describing his visits to several other planets. Each planet is inhabited by a different character, such as a king, a vain man, a drunkard, a businessman, a geographer, and a fox. Through these encounters, the Prince learns valuable lessons about love, responsibility, and the nature of adult behavior.\n",
    "\n",
    "On Earth, the Little Prince meets various creatures, including a fox, who teaches him about relationships and the importance of taming, which means building ties with others. The fox's famous line, \"You become responsible, forever, for what you have tamed,\" resonates with the Prince's feelings for his rose.\n",
    "\n",
    "Ultimately, the Little Prince realizes that the essence of life is often invisible and can only be seen with the heart. After sharing his wisdom with the pilot, he prepares to return to his asteroid and his beloved rose. The story concludes with the pilot reflecting on the lessons learned from the Little Prince and the enduring impact of their friendship.\n",
    "\n",
    "The narrative is a beautifully simple yet profound exploration of love, loss, and the importance of seeing beyond the surface of things.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7160bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. 인코딩 처리 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3760a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. 인코딩 처리 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426084de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 문장 토큰화\n",
    "# sent_tokenize() : 문장 단위로 토큰화\n",
    "sentences = sent_tokenize(raw_text)\n",
    "\n",
    "# 영어 불용어 리스트\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 단어 사전(key=단어, value=빈도수)\n",
    "vocab = {}\n",
    "\n",
    "# 토큰화/정제/정규화 처리 결과\n",
    "preprocessed_sentences = []\n",
    "\n",
    "# 토큰 만큼 반복\n",
    "for sent in sentences:\n",
    "    sent = sent.lower()  # 대소문자 정규화(소문자 변환)\n",
    "    words = word_tokenize(sent)  # 단어 토큰화\n",
    "    # 불용어 제거\n",
    "    words = [word for word in words if word not in stop_words] \n",
    "    # 단어 길이가 2 이하면 제거 (필터링)\n",
    "    filtered_tokens = [word for word in words if len(word) > 2]\n",
    "    \n",
    "    # vocab 사전에 단어가 없으면 추가, 있으면 빈도수 증가\n",
    "    for word in filtered_tokens:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1\n",
    "            \n",
    "    preprocessed_sentences.append(filtered_tokens)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6628c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_for_encoding(text, min_word_length=2, language='english'):\n",
    "    \"\"\"\n",
    "    텍스트를 정수 인코딩을 위해 전처리하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): 원본 텍스트\n",
    "    - min_word_length (int): 최소 단어 길이 (기본값: 2)\n",
    "    - language (str): 불용어 언어 (기본값: 'english')\n",
    "    \n",
    "    Returns:\n",
    "    - vocab (dict): 단어별 빈도수 딕셔너리\n",
    "    - preprocessed_sentences (list): 전처리된 문장들의 리스트\n",
    "    \"\"\"\n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    # 문장 토큰화\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # 불용어 리스트\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    \n",
    "    # 단어 사전(key=단어, value=빈도수)\n",
    "    vocab = {}\n",
    "    \n",
    "    # 토큰화/정제/정규화 처리 결과\n",
    "    preprocessed_sentences = []\n",
    "    \n",
    "    # 각 문장을 처리\n",
    "    for sent in sentences:\n",
    "        sent = sent.lower()  # 대소문자 정규화(소문자 변환)\n",
    "        words = word_tokenize(sent)  # 단어 토큰화\n",
    "        \n",
    "        # 불용어 제거 및 단어 길이 필터링\n",
    "        filtered_tokens = [\n",
    "            word for word in words \n",
    "            if word not in stop_words and len(word) > min_word_length\n",
    "        ]\n",
    "        \n",
    "        # vocab 사전에 단어 빈도수 추가\n",
    "        for word in filtered_tokens:\n",
    "            vocab[word] = vocab.get(word, 0) + 1\n",
    "            \n",
    "        preprocessed_sentences.append(filtered_tokens)\n",
    "    \n",
    "    return vocab, preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d7adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 단어 사전 크기: 109\n",
      "\n",
      "🔤 상위 10개 빈도수 단어:\n",
      "  prince: 9회\n",
      "  little: 6회\n",
      "  pilot: 4회\n",
      "  rose: 3회\n",
      "  fox: 3회\n",
      "  young: 2회\n",
      "  planet: 2회\n",
      "  earth: 2회\n",
      "  story: 2회\n",
      "  plane: 2회\n",
      "\n",
      "📄 전처리된 문장 수: 13\n",
      "📝 첫 번째 문장 예시: ['little', 'prince', 'written', 'antoine', 'saint-exupéry', 'poetic', 'tale', 'young', 'prince', 'travels']...\n"
     ]
    }
   ],
   "source": [
    "# 함수를 사용하여 전처리 수행\n",
    "vocab, preprocessed_sentences = preprocess_text_for_encoding(raw_text)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"📊 단어 사전 크기:\", len(vocab))\n",
    "print(\"\\n🔤 상위 10개 빈도수 단어:\")\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "for word, freq in sorted_vocab[:10]:\n",
    "    print(f\"  {word}: {freq}회\")\n",
    "\n",
    "print(f\"\\n📄 전처리된 문장 수: {len(preprocessed_sentences)}\")\n",
    "print(f\"📝 첫 번째 문장 예시: {preprocessed_sentences[0][:10]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
